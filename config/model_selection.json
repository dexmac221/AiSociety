{
  "_metadata": {
    "last_updated": "2025-09-05",
    "update_notes": "Updated with latest models from letest_models.json including Qwen2.5/3, Phi-4, Gemma-3, Hermes-4, and others",
    "new_categories": ["multimodal_specialists", "efficiency_specialists"],
    "featured_models": ["qwen2.5-coder:7b", "phi-4:14b", "qwen2.5-omni:7b", "hermes-4:14b"],
    "total_models": 14
  },
  
  "model_selection_strategies": {
    "gpt41_mini_routing": {
      "enabled": true,
      "description": "Use GPT-4.1-mini for intelligent model routing",
      "confidence_threshold": 0.75,
      "fallback_to_local": true,
      "cache_decisions": true,
      "prompt_template": "advanced_dynamic"
    },
    
    "local_keyword_routing": {
      "enabled": true,
      "description": "Fallback keyword-based routing",
      "keywords": {
        "coding": ["code", "python", "javascript", "debug", "function", "class", "programming", "algorithm"],
        "math": ["equation", "calculate", "solve", "mathematics", "algebra", "calculus", "reasoning", "proof"],
        "creative": ["story", "write", "creative", "poem", "narrative", "fiction", "roleplay", "uncensored"],
        "reasoning": ["analyze", "logic", "reason", "problem", "think", "deduce", "chain", "thought"],
        "general": ["explain", "what", "how", "describe", "tell", "help", "instruction", "question"],
        "multimodal": ["image", "audio", "video", "vision", "voice", "picture", "sound", "visual"],
        "efficiency": ["fast", "quick", "small", "mobile", "edge", "lightweight", "minimal"]
      }
    },
    
    "performance_based_routing": {
      "enabled": true,
      "description": "Route based on historical performance",
      "min_sample_size": 5,
      "success_weight": 0.6,
      "speed_weight": 0.4
    }
  },

  "model_categories": {
    "coding_specialists": {
      "primary": [
        {
          "name": "qwen2.5-coder:7b",
          "specializations": ["python", "javascript", "debugging", "code_review"],
          "performance_score": 92,
          "size": "4.7GB",
          "context": 32768,
          "priority": 1
        },
        {
          "name": "deepseek-coder-v2:16b",
          "specializations": ["complex_algorithms", "system_programming", "optimization"],
          "performance_score": 95,
          "size": "9.0GB",
          "context": 32768,
          "priority": 2
        },
        {
          "name": "codellama:7b",
          "specializations": ["general_coding", "documentation", "refactoring"],
          "performance_score": 88,
          "size": "3.8GB",
          "context": 16384,
          "priority": 3
        }
      ]
    },

    "math_specialists": {
      "primary": [
        {
          "name": "phi-4:14b",
          "specializations": ["math", "reasoning", "efficiency", "calculations"],
          "performance_score": 94,
          "size": "8GB",
          "context": 16000,
          "priority": 1,
          "notes": "Microsoft Phi-4 - Excellent math performance"
        },
        {
          "name": "qwen2.5:7b",
          "specializations": ["algebra", "calculus", "statistics", "problem_solving"],
          "performance_score": 90,
          "size": "4.4GB",
          "context": 131072,
          "priority": 2
        },
        {
          "name": "phi3:mini",
          "specializations": ["quick_calculations", "basic_math", "logic"],
          "performance_score": 85,
          "size": "2.3GB",
          "context": 8192,
          "priority": 3
        }
      ]
    },

    "creative_specialists": {
      "primary": [
        {
          "name": "hermes-4:14b",
          "specializations": ["creative_writing", "uncensored", "storytelling", "roleplay"],
          "performance_score": 93,
          "size": "8GB",
          "context": 128000,
          "priority": 1,
          "notes": "NousResearch Hermes-4 - Latest creative model"
        },
        {
          "name": "llama3.2:3b",
          "specializations": ["storytelling", "creative_writing", "brainstorming"],
          "performance_score": 87,
          "size": "2.0GB",
          "context": 128000,
          "priority": 2
        },
        {
          "name": "neural-chat:7b",
          "specializations": ["dialogue", "conversation", "roleplay"],
          "performance_score": 89,
          "size": "4.1GB",
          "context": 32768,
          "priority": 3
        },
        {
          "name": "yi:9b",
          "specializations": ["long_form_content", "poetry", "fiction"],
          "performance_score": 91,
          "size": "5.0GB",
          "context": 32768,
          "priority": 4
        }
      ]
    },

    "general_purpose": {
      "primary": [
        {
          "name": "qwen2.5:7b",
          "specializations": ["instruction_following", "multilingual", "reasoning", "general_qa"],
          "performance_score": 92,
          "size": "4.4GB",
          "context": 131072,
          "priority": 1,
          "notes": "Qwen2.5-7B-Instruct - Excellent general purpose model"
        },
        {
          "name": "llama3.1:8b",
          "specializations": ["reasoning", "code", "multilingual", "complex_tasks"],
          "performance_score": 90,
          "size": "4.7GB",
          "context": 128000,
          "priority": 2,
          "notes": "Llama-3.1-8B-Instruct"
        },
        {
          "name": "llama3.2:3b",
          "specializations": ["general_qa", "explanations", "summaries", "efficiency"],
          "performance_score": 86,
          "size": "2.0GB",
          "context": 128000,
          "priority": 3
        },
        {
          "name": "mistral:7b",
          "specializations": ["reasoning", "analysis", "research", "function_calling"],
          "performance_score": 88,
          "size": "4.1GB",
          "context": 32768,
          "priority": 4
        },
        {
          "name": "openai-gpt-oss:20b",
          "specializations": ["general_purpose", "reasoning", "function_calling", "complex_tasks"],
          "performance_score": 91,
          "size": "12GB",
          "context": 32000,
          "priority": 5,
          "notes": "OpenAI OSS 20B - RTX 3090 compatible"
        }
      ]
    },

    "reasoning_specialists": {
      "primary": [
        {
          "name": "openai-gpt-oss:20b",
          "specializations": ["general_purpose", "reasoning", "function_calling", "complex_analysis"],
          "performance_score": 91,
          "size": "12GB",
          "context": 32000,
          "priority": 1,
          "notes": "OpenAI OSS 20B - Advanced reasoning, RTX 3090 compatible"
        },
        {
          "name": "mixtral:8x7b",
          "specializations": ["multilingual", "code", "efficiency", "expert_mixture"],
          "performance_score": 89,
          "size": "26GB",
          "context": 32768,
          "priority": 2,
          "notes": "Mixtral 8x7B - Mixture of Experts architecture"
        }
      ]
    },

    "multimodal_specialists": {
      "primary": [
        {
          "name": "qwen2.5-omni:7b",
          "specializations": ["multimodal", "real_time_voice", "streaming", "text", "image", "audio", "video"],
          "performance_score": 95,
          "size": "4.4GB",
          "context": 128000,
          "priority": 1,
          "notes": "Qwen2.5-Omni - Advanced multimodal capabilities"
        },
        {
          "name": "gemma3:27b",
          "specializations": ["multilingual", "multimodal", "function_calling", "text", "image"],
          "performance_score": 93,
          "size": "16GB",
          "context": 128000,
          "priority": 2,
          "notes": "Gemma-3-27B-IT - Large multimodal model"
        },
        {
          "name": "gemma3:4b",
          "specializations": ["efficiency", "multilingual", "multimodal", "text", "image"],
          "performance_score": 88,
          "size": "2.5GB",
          "context": 128000,
          "priority": 3,
          "notes": "Gemma-3-4B-IT - Efficient multimodal"
        }
      ]
    },

    "efficiency_specialists": {
      "primary": [
        {
          "name": "gemma3:1b",
          "specializations": ["efficiency", "edge_deployment", "low_resource"],
          "performance_score": 82,
          "size": "0.7GB",
          "context": 32000,
          "priority": 1,
          "notes": "Gemma-3-1B-IT - Ultra-efficient model"
        },
        {
          "name": "apple-fastvlm:7b",
          "specializations": ["efficiency", "mobile", "on_device"],
          "performance_score": 85,
          "size": "4GB",
          "context": 32000,
          "priority": 2,
          "notes": "Apple FastVLM - Mobile optimized"
        },
        {
          "name": "nvidia-nemotron-nano:12b",
          "specializations": ["efficiency", "enterprise", "reasoning"],
          "performance_score": 90,
          "size": "7GB",
          "context": 128000,
          "priority": 3,
          "notes": "NVIDIA Nemotron Nano - Enterprise grade"
        }
      ]
    }
  },

  "routing_rules": {
    "size_constraints": {
      "prefer_under_5gb": true,
      "max_size_gb": 50,
      "auto_download_under_gb": 8,
      "prompt_for_large_models_gb": 15,
      "notes": "Updated for latest large models like DeepSeek-R1"
    },
    
    "performance_thresholds": {
      "min_score_for_complex": 85,
      "min_score_for_simple": 75,
      "prefer_local_if_score_diff_under": 10
    },
    
    "download_policies": {
      "auto_download_essential": true,
      "prompt_for_large_models": true,
      "max_concurrent_downloads": 1,
      "retry_failed_downloads": 3
    }
  },

  "gpt4o_routing_prompts": {
    "system_prompt": "You are an AI model router for a local AI system. Analyze queries and recommend the optimal local model based on specialization, performance, and availability.",
    
    "query_analysis_template": "Analyze this query: '{query}'\n\nAvailable models:\n{model_inventory}\n\nRecommend the best model with reasoning in JSON format.",
    
    "response_format": {
      "required_fields": ["recommended_model", "confidence", "reasoning", "query_type"],
      "optional_fields": ["alternatives", "download_if_needed", "complexity_score"],
      "confidence_scale": "0.0 to 1.0"
    }
  },

  "fallback_strategy": {
    "order": [
      "gpt41_mini_routing",
      "performance_based_routing", 
      "local_keyword_routing",
      "default_model"
    ],
    
    "default_models": {
      "coding": "qwen2.5-coder:7b",
      "math": "phi-4:14b",
      "creative": "hermes-4:14b",
      "general": "qwen2.5:7b",
      "multimodal": "qwen2.5-omni:7b",
      "efficiency": "gemma3:1b",
      "reasoning": "openai-gpt-oss:20b"
    },
    
    "emergency_fallback": "qwen2.5:7b"
  }
}
